{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Импорт необходимых библиотек и создание глобальных переменных**","metadata":{}},{"cell_type":"code","source":"!pip install segmentation_models\n!pip install ultralytics","metadata":{"execution":{"iopub.status.busy":"2023-05-21T06:15:59.341792Z","iopub.execute_input":"2023-05-21T06:15:59.342162Z","iopub.status.idle":"2023-05-21T06:16:27.260196Z","shell.execute_reply.started":"2023-05-21T06:15:59.342130Z","shell.execute_reply":"2023-05-21T06:16:27.258957Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting segmentation_models\n  Downloading segmentation_models-1.0.1-py3-none-any.whl (33 kB)\nCollecting efficientnet==1.0.0\n  Downloading efficientnet-1.0.0-py3-none-any.whl (17 kB)\nCollecting image-classifiers==1.0.0\n  Downloading image_classifiers-1.0.0-py3-none-any.whl (19 kB)\nCollecting keras-applications<=1.0.8,>=1.0.7\n  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: scikit-image in /opt/conda/lib/python3.10/site-packages (from efficientnet==1.0.0->segmentation_models) (0.20.0)\nRequirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.10/site-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation_models) (1.23.5)\nRequirement already satisfied: h5py in /opt/conda/lib/python3.10/site-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation_models) (3.8.0)\nRequirement already satisfied: imageio>=2.4.1 in /opt/conda/lib/python3.10/site-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (2.27.0)\nRequirement already satisfied: tifffile>=2019.7.26 in /opt/conda/lib/python3.10/site-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (2023.3.21)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (21.3)\nRequirement already satisfied: PyWavelets>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (1.4.1)\nRequirement already satisfied: pillow>=9.0.1 in /opt/conda/lib/python3.10/site-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (9.5.0)\nRequirement already satisfied: networkx>=2.8 in /opt/conda/lib/python3.10/site-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (3.1)\nRequirement already satisfied: scipy>=1.8 in /opt/conda/lib/python3.10/site-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (1.9.3)\nRequirement already satisfied: lazy_loader>=0.1 in /opt/conda/lib/python3.10/site-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (0.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->scikit-image->efficientnet==1.0.0->segmentation_models) (3.0.9)\nInstalling collected packages: keras-applications, image-classifiers, efficientnet, segmentation_models\nSuccessfully installed efficientnet-1.0.0 image-classifiers-1.0.0 keras-applications-1.0.8 segmentation_models-1.0.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mCollecting ultralytics\n  Downloading ultralytics-8.0.105-py3-none-any.whl (586 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m586.5/586.5 kB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: seaborn>=0.11.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (0.12.2)\nRequirement already satisfied: torch>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.0.0)\nRequirement already satisfied: Pillow>=7.1.2 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (9.5.0)\nRequirement already satisfied: scipy>=1.4.1 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (1.9.3)\nCollecting opencv-python>=4.6.0\n  Downloading opencv_python-4.7.0.72-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (61.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.8/61.8 MB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: tqdm>=4.64.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (4.64.1)\nRequirement already satisfied: torchvision>=0.8.1 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (0.15.1)\nRequirement already satisfied: requests>=2.23.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.28.2)\nRequirement already satisfied: pandas>=1.1.4 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (1.5.3)\nRequirement already satisfied: sentry-sdk in /opt/conda/lib/python3.10/site-packages (from ultralytics) (1.20.0)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from ultralytics) (5.9.4)\nRequirement already satisfied: matplotlib>=3.2.2 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (3.6.3)\nRequirement already satisfied: PyYAML>=5.3.1 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (6.0)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.2.2->ultralytics) (2.8.2)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.2.2->ultralytics) (1.0.7)\nRequirement already satisfied: numpy>=1.19 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.2.2->ultralytics) (1.23.5)\nRequirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.2.2->ultralytics) (3.0.9)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.2.2->ultralytics) (21.3)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.2.2->ultralytics) (4.39.3)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.2.2->ultralytics) (0.11.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.2.2->ultralytics) (1.4.4)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2023.3)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (2022.12.7)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (1.26.15)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.4)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (2.1.1)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.0->ultralytics) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.0->ultralytics) (3.1.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.0->ultralytics) (4.5.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.0->ultralytics) (3.11.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.0->ultralytics) (1.11.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.2.2->ultralytics) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.7.0->ultralytics) (2.1.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.7.0->ultralytics) (1.3.0)\nInstalling collected packages: opencv-python, ultralytics\n  Attempting uninstall: opencv-python\n    Found existing installation: opencv-python 4.5.4.60\n    Uninstalling opencv-python-4.5.4.60:\n      Successfully uninstalled opencv-python-4.5.4.60\nSuccessfully installed opencv-python-4.7.0.72 ultralytics-8.0.105\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import absl.logging\nabsl.logging.set_verbosity(absl.logging.ERROR)\n\nimport os\nos.environ[\"SM_FRAMEWORK\"] = \"tf.keras\"\nfrom pathlib import Path\nfrom math import ceil\n\nimport pandas as pd\nimport numpy as np\nimport scipy\nimport keras\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.image\n\nfrom sklearn.metrics import confusion_matrix\n\nimport tensorflow as tf\n\nimport segmentation_models as sm\nfrom segmentation_models.losses import bce_jaccard_loss\nfrom segmentation_models.metrics import iou_score\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, load_img\nfrom tensorflow.keras.models import Model, Sequential, load_model\nfrom tensorflow.keras.layers import (Input, Activation, BatchNormalization, concatenate,\n                                     Flatten, Dense, Dropout,\n                                     Conv2DTranspose, MaxPooling2D, Conv2D, MaxPool2D, AveragePooling2D)\nfrom tensorflow.keras.metrics import Precision, Recall\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom tensorflow.keras.utils import Sequence, img_to_array\n\nfrom tqdm import tqdm\n\nfrom keras import backend as K\nfrom keras.backend import clear_session\n\nBATCH_SIZE = 32\nIMAGE_SIZE = (380, 380)\nEPOCHS = 20","metadata":{"execution":{"iopub.status.busy":"2023-05-21T06:16:27.264357Z","iopub.execute_input":"2023-05-21T06:16:27.264817Z","iopub.status.idle":"2023-05-21T06:16:34.693555Z","shell.execute_reply.started":"2023-05-21T06:16:27.264771Z","shell.execute_reply":"2023-05-21T06:16:34.691707Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"},{"name":"stdout","text":"Segmentation Models: using `tf.keras` framework.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Полезные ссылки**","metadata":{}},{"cell_type":"markdown","source":"Свёрточные нейронные сети в классификации изображений: https://habr.com/ru/post/348000/\n\nСверточные нейронные сети: https://neerc.ifmo.ru/wiki/index.php?title=%D0%A1%D0%B2%D0%B5%D1%80%D1%82%D0%BE%D1%87%D0%BD%D1%8B%D0%B5_%D0%BD%D0%B5%D0%B9%D1%80%D0%BE%D0%BD%D0%BD%D1%8B%D0%B5_%D1%81%D0%B5%D1%82%D0%B8\n\nСуть нейронных сетей на основе свёртки: https://habr.com/ru/post/309508/","metadata":{}},{"cell_type":"markdown","source":"## Загрузка данных","metadata":{}},{"cell_type":"markdown","source":"Набор данных Food-5K: https://www.kaggle.com/datasets/trolukovich/food5k-image-dataset?resource=download\n\nДанная ссылка позволяет также увидеть готовые реализации, из которых можно составить подавляющую часть работы","metadata":{}},{"cell_type":"code","source":"data_path = \"/kaggle/input/base-digital-swan/\"\npath_segmentation_model = 'segmentation_model/'\npath_classification_model = 'classification_model/'","metadata":{"execution":{"iopub.status.busy":"2023-05-21T06:16:34.695012Z","iopub.execute_input":"2023-05-21T06:16:34.695702Z","iopub.status.idle":"2023-05-21T06:16:34.700045Z","shell.execute_reply.started":"2023-05-21T06:16:34.695665Z","shell.execute_reply":"2023-05-21T06:16:34.699061Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"directories = os.listdir(data_path)\nnumberof_images={}\ndir_classes={}\n\nfor directory in directories:\n    dir_classes[directory] = os.listdir(data_path + directory + \"/\")\n    for class_name in dir_classes[directory]:\n        full_class_name = directory + \"/\" + class_name\n        numberof_images[full_class_name] = len(os.listdir(data_path + directory + \"/\" + class_name))\nimages_each_class=pd.DataFrame(numberof_images.values(),index=numberof_images.keys(),columns=[\"Количество изображений\"])\nprint(\"Содержание данных\", images_each_class, sep=\"\\n\")","metadata":{"execution":{"iopub.status.busy":"2023-05-21T06:16:34.702734Z","iopub.execute_input":"2023-05-21T06:16:34.704087Z","iopub.status.idle":"2023-05-21T06:16:35.408871Z","shell.execute_reply.started":"2023-05-21T06:16:34.704002Z","shell.execute_reply":"2023-05-21T06:16:35.407922Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Содержание данных\n                Количество изображений\nsmall1/images                     3002\nsmall1/masks                      3002\nklikun0/images                    3025\nklikun0/masks                     3025\nshipun2/images                    3011\nshipun2/masks                     3011\n","output_type":"stream"}]},{"cell_type":"code","source":"full_data_path = Path(data_path)\nimage_data_path = list(full_data_path.glob(\"**/images/*.jpg\"))\nimage_label_path = list(map(lambda x: os.path.split(os.path.split(x)[0])[0], image_data_path))\nimage_label_path = [elem.split('/')[-1] for elem in image_label_path]\nfull_data = pd.DataFrame({\"image_data\": image_data_path, \"label\": image_label_path}).astype(\"str\")\nfull_data = full_data.sample(frac=1).reset_index(drop=True)\nfull_data","metadata":{"execution":{"iopub.status.busy":"2023-05-21T06:16:35.411182Z","iopub.execute_input":"2023-05-21T06:16:35.412125Z","iopub.status.idle":"2023-05-21T06:16:47.747898Z","shell.execute_reply.started":"2023-05-21T06:16:35.412072Z","shell.execute_reply":"2023-05-21T06:16:47.746976Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                                             image_data    label\n0     /kaggle/input/base-digital-swan/shipun2/images...  shipun2\n1     /kaggle/input/base-digital-swan/klikun0/images...  klikun0\n2     /kaggle/input/base-digital-swan/small1/images/...   small1\n3     /kaggle/input/base-digital-swan/shipun2/images...  shipun2\n4     /kaggle/input/base-digital-swan/shipun2/images...  shipun2\n...                                                 ...      ...\n9033  /kaggle/input/base-digital-swan/klikun0/images...  klikun0\n9034  /kaggle/input/base-digital-swan/shipun2/images...  shipun2\n9035  /kaggle/input/base-digital-swan/shipun2/images...  shipun2\n9036  /kaggle/input/base-digital-swan/small1/images/...   small1\n9037  /kaggle/input/base-digital-swan/klikun0/images...  klikun0\n\n[9038 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_data</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>/kaggle/input/base-digital-swan/shipun2/images...</td>\n      <td>shipun2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>/kaggle/input/base-digital-swan/klikun0/images...</td>\n      <td>klikun0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>/kaggle/input/base-digital-swan/small1/images/...</td>\n      <td>small1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>/kaggle/input/base-digital-swan/shipun2/images...</td>\n      <td>shipun2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>/kaggle/input/base-digital-swan/shipun2/images...</td>\n      <td>shipun2</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9033</th>\n      <td>/kaggle/input/base-digital-swan/klikun0/images...</td>\n      <td>klikun0</td>\n    </tr>\n    <tr>\n      <th>9034</th>\n      <td>/kaggle/input/base-digital-swan/shipun2/images...</td>\n      <td>shipun2</td>\n    </tr>\n    <tr>\n      <th>9035</th>\n      <td>/kaggle/input/base-digital-swan/shipun2/images...</td>\n      <td>shipun2</td>\n    </tr>\n    <tr>\n      <th>9036</th>\n      <td>/kaggle/input/base-digital-swan/small1/images/...</td>\n      <td>small1</td>\n    </tr>\n    <tr>\n      <th>9037</th>\n      <td>/kaggle/input/base-digital-swan/klikun0/images...</td>\n      <td>klikun0</td>\n    </tr>\n  </tbody>\n</table>\n<p>9038 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"idx_train = int(len(full_data) * 0.8)\nidx_valid = idx_train + int(len(full_data) * 0.2)","metadata":{"execution":{"iopub.status.busy":"2023-05-21T06:16:47.749243Z","iopub.execute_input":"2023-05-21T06:16:47.749664Z","iopub.status.idle":"2023-05-21T06:16:47.754994Z","shell.execute_reply.started":"2023-05-21T06:16:47.749628Z","shell.execute_reply":"2023-05-21T06:16:47.753930Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"train = full_data.iloc[:idx_train, :]\nvalid = full_data.iloc[idx_train:idx_valid, :]\ntest = full_data.iloc[idx_valid:, :]","metadata":{"execution":{"iopub.status.busy":"2023-05-21T06:16:47.756623Z","iopub.execute_input":"2023-05-21T06:16:47.757404Z","iopub.status.idle":"2023-05-21T06:16:47.770622Z","shell.execute_reply.started":"2023-05-21T06:16:47.757368Z","shell.execute_reply":"2023-05-21T06:16:47.769638Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"full_data = train\nfull_data","metadata":{"execution":{"iopub.status.busy":"2023-05-21T06:16:47.772076Z","iopub.execute_input":"2023-05-21T06:16:47.772472Z","iopub.status.idle":"2023-05-21T06:16:47.786882Z","shell.execute_reply.started":"2023-05-21T06:16:47.772434Z","shell.execute_reply":"2023-05-21T06:16:47.785766Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"                                             image_data    label\n0     /kaggle/input/base-digital-swan/shipun2/images...  shipun2\n1     /kaggle/input/base-digital-swan/klikun0/images...  klikun0\n2     /kaggle/input/base-digital-swan/small1/images/...   small1\n3     /kaggle/input/base-digital-swan/shipun2/images...  shipun2\n4     /kaggle/input/base-digital-swan/shipun2/images...  shipun2\n...                                                 ...      ...\n7225  /kaggle/input/base-digital-swan/shipun2/images...  shipun2\n7226  /kaggle/input/base-digital-swan/shipun2/images...  shipun2\n7227  /kaggle/input/base-digital-swan/small1/images/...   small1\n7228  /kaggle/input/base-digital-swan/shipun2/images...  shipun2\n7229  /kaggle/input/base-digital-swan/klikun0/images...  klikun0\n\n[7230 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_data</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>/kaggle/input/base-digital-swan/shipun2/images...</td>\n      <td>shipun2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>/kaggle/input/base-digital-swan/klikun0/images...</td>\n      <td>klikun0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>/kaggle/input/base-digital-swan/small1/images/...</td>\n      <td>small1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>/kaggle/input/base-digital-swan/shipun2/images...</td>\n      <td>shipun2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>/kaggle/input/base-digital-swan/shipun2/images...</td>\n      <td>shipun2</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7225</th>\n      <td>/kaggle/input/base-digital-swan/shipun2/images...</td>\n      <td>shipun2</td>\n    </tr>\n    <tr>\n      <th>7226</th>\n      <td>/kaggle/input/base-digital-swan/shipun2/images...</td>\n      <td>shipun2</td>\n    </tr>\n    <tr>\n      <th>7227</th>\n      <td>/kaggle/input/base-digital-swan/small1/images/...</td>\n      <td>small1</td>\n    </tr>\n    <tr>\n      <th>7228</th>\n      <td>/kaggle/input/base-digital-swan/shipun2/images...</td>\n      <td>shipun2</td>\n    </tr>\n    <tr>\n      <th>7229</th>\n      <td>/kaggle/input/base-digital-swan/klikun0/images...</td>\n      <td>klikun0</td>\n    </tr>\n  </tbody>\n</table>\n<p>7230 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Создание моделей","metadata":{}},{"cell_type":"code","source":"from ultralytics import YOLO\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2023-05-21T06:16:47.788502Z","iopub.execute_input":"2023-05-21T06:16:47.788833Z","iopub.status.idle":"2023-05-21T06:16:54.080324Z","shell.execute_reply.started":"2023-05-21T06:16:47.788804Z","shell.execute_reply":"2023-05-21T06:16:54.079374Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"model = YOLO(\"yolov8n.pt\")","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-05-21T06:16:54.084465Z","iopub.execute_input":"2023-05-21T06:16:54.085006Z","iopub.status.idle":"2023-05-21T06:16:56.076201Z","shell.execute_reply.started":"2023-05-21T06:16:54.084979Z","shell.execute_reply":"2023-05-21T06:16:56.075251Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt to yolov8n.pt...\n100%|██████████| 6.23M/6.23M [00:00<00:00, 13.6MB/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"images_list = list(full_data['image_data'])","metadata":{"execution":{"iopub.status.busy":"2023-05-21T06:16:56.077563Z","iopub.execute_input":"2023-05-21T06:16:56.078010Z","iopub.status.idle":"2023-05-21T06:16:56.084664Z","shell.execute_reply.started":"2023-05-21T06:16:56.077976Z","shell.execute_reply":"2023-05-21T06:16:56.083505Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"classes = ['maly', 'klikun', 'shipun']\nif not os.path.isdir('new_data'):\n    os.mkdir('new_data')\nfor elem in classes:\n    if not os.path.isdir(f'new_data/{elem}'):\n        os.mkdir(f'new_data/{elem}')\n    if not os.path.isdir(f'new_data/{elem}/images'):\n        os.mkdir(f'new_data/{elem}/images')","metadata":{"execution":{"iopub.status.busy":"2023-05-21T06:16:56.086089Z","iopub.execute_input":"2023-05-21T06:16:56.086737Z","iopub.status.idle":"2023-05-21T06:16:56.094370Z","shell.execute_reply.started":"2023-05-21T06:16:56.086704Z","shell.execute_reply":"2023-05-21T06:16:56.093357Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"img_dict = {}\n\ndef augment_images(model, img_path):\n        \n    img_info = img_path.split('/')\n    category, img_name = img_info[4], img_info[3]\n\n    try:\n\n        prediction = model.predict(plt.imread(img_path), verbose=False)\n\n        real_boxes = []\n        for idx in range(len(prediction[0].boxes.data)):\n            real_boxes.append(prediction[0].boxes.data[idx][0:4])\n\n        int_points = []\n        for tensor in real_boxes:\n            int_points.append(list(\n                [int(tensor[0]), int(tensor[2]), int(tensor[1]), int(tensor[3])],\n            ))\n\n        all_images = []\n        for idx in range(len(int_points)):\n            all_images.append(prediction[0].orig_img[int_points[idx][2]:int_points[idx][3], int_points[idx][0]:int_points[idx][1]])\n\n        #img_dict[img_path] = {'category': category, 'images': all_images}\n        \n        keys, values = [img_path], [{'category': category, 'images': all_images}]\n        \n        df = pd.DataFrame()\n        for idx, img in enumerate(keys):\n            for augment in values[idx]['images']:\n                df = df.append({'img_path': img, 'augment': augment, 'label': values[idx]['category']}, ignore_index = True)\n        try:\n            df['img_path'] = df['img_path'].str.replace('data_baseline', 'new_data')\n        except KeyError:\n            return\n        \n        counter = 0\n        cur_path = df['img_path'][0]\n        length_df = len(df)\n        for idx in range(length_df):\n            #print(f'Итерация {idx}/{length_df}')\n            next_path = df['img_path'][idx]\n            if next_path != cur_path:\n                cur_path = next_path\n                counter = 0\n\n            splitter = next_path.split('/')\n            name = splitter[4][:-1]\n            if name == 'small':\n                name = 'maly'\n            first_path = f'/kaggle/working/new_data/{name}/'\n\n            second_path = list(splitter[-1].partition(\".jpg\"))[:-1]\n            if counter == 0:\n                second_path = ''.join(second_path)\n            else:\n                second_path = f'{second_path[0]} ({counter}){second_path[1]}'\n\n            counter += 1\n            full_path = first_path + second_path\n\n            plt.imsave(full_path, df['augment'][idx])\n\n    except RuntimeError:\n        pass","metadata":{"execution":{"iopub.status.busy":"2023-05-21T06:16:56.095931Z","iopub.execute_input":"2023-05-21T06:16:56.096273Z","iopub.status.idle":"2023-05-21T06:16:56.111299Z","shell.execute_reply.started":"2023-05-21T06:16:56.096242Z","shell.execute_reply":"2023-05-21T06:16:56.110385Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"for elem in tqdm(images_list):\n    augment_images(model, elem)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-05-21T06:16:56.112425Z","iopub.execute_input":"2023-05-21T06:16:56.113724Z","iopub.status.idle":"2023-05-21T06:21:56.183915Z","shell.execute_reply.started":"2023-05-21T06:16:56.113678Z","shell.execute_reply":"2023-05-21T06:21:56.182972Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"100%|██████████| 7230/7230 [05:00<00:00, 24.10it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"# keys, values = list(img_dict.keys()), list(img_dict.values())","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-05-21T06:21:56.185492Z","iopub.execute_input":"2023-05-21T06:21:56.185853Z","iopub.status.idle":"2023-05-21T06:21:56.191021Z","shell.execute_reply.started":"2023-05-21T06:21:56.185819Z","shell.execute_reply":"2023-05-21T06:21:56.189991Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# df = pd.DataFrame()\n# for idx, img in enumerate(keys):\n#     for augment in values[idx]['images']:\n#         df = df.append({'img_path': img, 'augment': augment, 'label': values[idx]['category']}, ignore_index = True)\n\n# df['img_path'] = df['img_path'].str.replace('data_baseline', 'new_data')\n# df","metadata":{"execution":{"iopub.status.busy":"2023-05-21T06:21:56.192648Z","iopub.execute_input":"2023-05-21T06:21:56.193683Z","iopub.status.idle":"2023-05-21T06:21:56.200091Z","shell.execute_reply.started":"2023-05-21T06:21:56.193649Z","shell.execute_reply":"2023-05-21T06:21:56.199144Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# counter = 0\n# cur_path = df['img_path'][0]\n# length_df = len(df)\n# for idx in tqdm(range(length_df)):\n#     #print(f'Итерация {idx}/{length_df}')\n#     next_path = df['img_path'][idx]\n#     if next_path != cur_path:\n#         cur_path = next_path\n#         counter = 0\n    \n#     splitter = next_path.split('/')\n#     name = splitter[4][:-1]\n#     if name == 'small':\n#         name = 'maly'\n#     first_path = f'/kaggle/working/new_data/{name}/'\n    \n#     second_path = list(splitter[-1].partition(\".jpg\"))[:-1]\n#     if counter == 0:\n#         second_path = ''.join(second_path)\n#     else:\n#         second_path = f'{second_path[0]} ({counter}){second_path[1]}'\n\n#     counter += 1\n#     full_path = first_path + second_path\n    \n#     plt.imsave(full_path, df['augment'][idx])","metadata":{"execution":{"iopub.status.busy":"2023-05-21T06:21:56.201622Z","iopub.execute_input":"2023-05-21T06:21:56.202014Z","iopub.status.idle":"2023-05-21T06:21:56.209318Z","shell.execute_reply.started":"2023-05-21T06:21:56.201982Z","shell.execute_reply":"2023-05-21T06:21:56.208385Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"new_data_path = 'new_data/'\nfull_data_path = Path(new_data_path)\nimage_data_path = list(full_data_path.glob(\"**/*.jpg\"))\nimage_label_path = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], image_data_path))\nimage_label_path = [elem.split('/')[0] for elem in image_label_path]\nfinal_image_data = pd.DataFrame({\"image_data\": image_data_path, \"label\": image_label_path}).astype(\"str\")\nfinal_image_data = final_image_data.sample(frac=1).reset_index(drop=True)\nfinal_image_data","metadata":{"execution":{"iopub.status.busy":"2023-05-21T06:21:56.210798Z","iopub.execute_input":"2023-05-21T06:21:56.211204Z","iopub.status.idle":"2023-05-21T06:21:56.438648Z","shell.execute_reply.started":"2023-05-21T06:21:56.211173Z","shell.execute_reply":"2023-05-21T06:21:56.437605Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"                               image_data   label\n0          new_data/klikun/3091446387.jpg  klikun\n1        new_data/maly/3733207005 (3).jpg    maly\n2             new_data/shipun/img_517.jpg  shipun\n3        new_data/maly/2838017119 (2).jpg    maly\n4      new_data/klikun/4009875989 (4).jpg  klikun\n...                                   ...     ...\n13690  new_data/klikun/2274373025 (1).jpg  klikun\n13691        new_data/maly/1960603870.jpg    maly\n13692        new_data/shipun/img_1260.jpg  shipun\n13693      new_data/klikun/2856786316.jpg  klikun\n13694      new_data/klikun/2604072834.jpg  klikun\n\n[13695 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_data</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>new_data/klikun/3091446387.jpg</td>\n      <td>klikun</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>new_data/maly/3733207005 (3).jpg</td>\n      <td>maly</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>new_data/shipun/img_517.jpg</td>\n      <td>shipun</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>new_data/maly/2838017119 (2).jpg</td>\n      <td>maly</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>new_data/klikun/4009875989 (4).jpg</td>\n      <td>klikun</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>13690</th>\n      <td>new_data/klikun/2274373025 (1).jpg</td>\n      <td>klikun</td>\n    </tr>\n    <tr>\n      <th>13691</th>\n      <td>new_data/maly/1960603870.jpg</td>\n      <td>maly</td>\n    </tr>\n    <tr>\n      <th>13692</th>\n      <td>new_data/shipun/img_1260.jpg</td>\n      <td>shipun</td>\n    </tr>\n    <tr>\n      <th>13693</th>\n      <td>new_data/klikun/2856786316.jpg</td>\n      <td>klikun</td>\n    </tr>\n    <tr>\n      <th>13694</th>\n      <td>new_data/klikun/2604072834.jpg</td>\n      <td>klikun</td>\n    </tr>\n  </tbody>\n</table>\n<p>13695 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"idx_train = int(len(final_image_data) * 0.8)\nidx_valid = idx_train + int(len(final_image_data) * 0.2)","metadata":{"execution":{"iopub.status.busy":"2023-05-21T06:21:56.440145Z","iopub.execute_input":"2023-05-21T06:21:56.440511Z","iopub.status.idle":"2023-05-21T06:21:56.445886Z","shell.execute_reply.started":"2023-05-21T06:21:56.440474Z","shell.execute_reply":"2023-05-21T06:21:56.444758Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"train = final_image_data.iloc[:idx_train, :]\nvalid = final_image_data.iloc[idx_train:idx_valid, :]\ntest = final_image_data.iloc[idx_valid:, :]","metadata":{"execution":{"iopub.status.busy":"2023-05-21T06:21:56.447380Z","iopub.execute_input":"2023-05-21T06:21:56.448428Z","iopub.status.idle":"2023-05-21T06:21:56.455941Z","shell.execute_reply.started":"2023-05-21T06:21:56.448388Z","shell.execute_reply":"2023-05-21T06:21:56.454869Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"### Преобразование для классификации","metadata":{}},{"cell_type":"code","source":"train_generator = ImageDataGenerator(rescale=1./255)\nvalid_generator = ImageDataGenerator(rescale=1./255)\ntest_generator = ImageDataGenerator(rescale=1./255)","metadata":{"execution":{"iopub.status.busy":"2023-05-21T06:21:56.457406Z","iopub.execute_input":"2023-05-21T06:21:56.457936Z","iopub.status.idle":"2023-05-21T06:21:56.465541Z","shell.execute_reply.started":"2023-05-21T06:21:56.457887Z","shell.execute_reply":"2023-05-21T06:21:56.464703Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"class_train_data = train_generator.flow_from_dataframe(dataframe=train,\n                                                 x_col=\"image_data\",\n                                                 y_col=\"label\",\n                                                 batch_size=BATCH_SIZE,\n                                                 class_mode=\"categorical\",  # Режим целевых показателей\n                                                 target_size=IMAGE_SIZE,\n                                                 color_mode=\"rgb\",\n                                                 shuffle=True)  # Необходимость перетасовки данных\n\nclass_valid_data = valid_generator.flow_from_dataframe(dataframe=valid,\n                                                 x_col=\"image_data\",\n                                                 y_col=\"label\",\n                                                 batch_size=BATCH_SIZE,\n                                                 class_mode=\"categorical\",  # Режим целевых показателей\n                                                 target_size=IMAGE_SIZE,\n                                                 color_mode=\"rgb\",\n                                                 shuffle=True)  # Необходимость перетасовки данных\n\n# class_test_data = test_generator.flow_from_dataframe(dataframe=test,\n#                                                x_col=\"image_data\",\n#                                                y_col=\"label\",\n#                                                batch_size=BATCH_SIZE,\n#                                                class_mode=\"categorical\",  # Режим целевых показателей\n#                                                target_size=IMAGE_SIZE,\n#                                                color_mode=\"rgb\",\n#                                                shuffle=False)  # Необходимость перетасовки данных","metadata":{"execution":{"iopub.status.busy":"2023-05-21T06:25:33.941014Z","iopub.execute_input":"2023-05-21T06:25:33.942031Z","iopub.status.idle":"2023-05-21T06:25:34.106260Z","shell.execute_reply.started":"2023-05-21T06:25:33.941985Z","shell.execute_reply":"2023-05-21T06:25:34.105155Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"Found 10956 validated image filenames belonging to 3 classes.\nFound 2739 validated image filenames belonging to 3 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"class_train_number = class_train_data.samples\nclass_valid_number = class_valid_data.samples","metadata":{"execution":{"iopub.status.busy":"2023-05-21T06:25:37.290249Z","iopub.execute_input":"2023-05-21T06:25:37.291294Z","iopub.status.idle":"2023-05-21T06:25:37.296554Z","shell.execute_reply.started":"2023-05-21T06:25:37.291241Z","shell.execute_reply":"2023-05-21T06:25:37.295370Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"### Обучение","metadata":{}},{"cell_type":"code","source":"classification_callbacks = [\n        EarlyStopping(patience=10, monitor='val_loss', mode='min'),\n        ModelCheckpoint(\n            path_classification_model,\n            save_weights_only=False,\n            monitor='val_loss',\n            mode='min',\n            save_best_only=True\n        ),\n    ]","metadata":{"execution":{"iopub.status.busy":"2023-05-21T06:25:40.383125Z","iopub.execute_input":"2023-05-21T06:25:40.384129Z","iopub.status.idle":"2023-05-21T06:25:40.389734Z","shell.execute_reply.started":"2023-05-21T06:25:40.384060Z","shell.execute_reply":"2023-05-21T06:25:40.388562Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"def plot_hist(hist):\n    plt.plot(hist.history[\"accuracy\"])\n    plt.plot(hist.history[\"val_accuracy\"])\n    plt.title(\"model accuracy\")\n    plt.ylabel(\"accuracy\")\n    plt.xlabel(\"epoch\")\n    plt.legend([\"train\", \"validation\"], loc=\"upper left\")\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-05-21T06:25:42.176459Z","iopub.execute_input":"2023-05-21T06:25:42.177168Z","iopub.status.idle":"2023-05-21T06:25:42.183319Z","shell.execute_reply.started":"2023-05-21T06:25:42.177125Z","shell.execute_reply":"2023-05-21T06:25:42.182357Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"## Модель 1","metadata":{}},{"cell_type":"code","source":"clear_session()\nmax_pool_model = Sequential()\n\nmax_pool_model.add(Conv2D(128, kernel_initializer='he_normal', kernel_size=(3, 3),\n                 input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3), activation='relu'))\nmax_pool_model.add(MaxPool2D(3, 3))\nmax_pool_model.add(Dropout(0.3))\n\nmax_pool_model.add(Conv2D(256, kernel_initializer='he_normal', kernel_size=(3, 3), activation='relu'))\nmax_pool_model.add(MaxPool2D(3, 3))\nmax_pool_model.add(Dropout(0.3))\n\nmax_pool_model.add(Conv2D(512, kernel_initializer='he_normal', kernel_size=(3, 3), activation='relu'))\nmax_pool_model.add(MaxPool2D(3, 3))\nmax_pool_model.add(Dropout(0.5))\n\nmax_pool_model.add(Flatten())\nmax_pool_model.add(Dense(128, activation='relu'))\nmax_pool_model.add(Dense(256, activation='relu'))\nmax_pool_model.add(Dense(3, activation='softmax'))","metadata":{"execution":{"iopub.status.busy":"2023-05-21T06:32:39.217835Z","iopub.execute_input":"2023-05-21T06:32:39.218238Z","iopub.status.idle":"2023-05-21T06:32:39.437370Z","shell.execute_reply.started":"2023-05-21T06:32:39.218206Z","shell.execute_reply":"2023-05-21T06:32:39.436429Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"max_pool_model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-05-21T06:32:42.512825Z","iopub.execute_input":"2023-05-21T06:32:42.513219Z","iopub.status.idle":"2023-05-21T06:32:42.551743Z","shell.execute_reply.started":"2023-05-21T06:32:42.513186Z","shell.execute_reply":"2023-05-21T06:32:42.551036Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n conv2d (Conv2D)             (None, 378, 378, 128)     3584      \n                                                                 \n max_pooling2d (MaxPooling2D  (None, 126, 126, 128)    0         \n )                                                               \n                                                                 \n dropout (Dropout)           (None, 126, 126, 128)     0         \n                                                                 \n conv2d_1 (Conv2D)           (None, 124, 124, 256)     295168    \n                                                                 \n max_pooling2d_1 (MaxPooling  (None, 41, 41, 256)      0         \n 2D)                                                             \n                                                                 \n dropout_1 (Dropout)         (None, 41, 41, 256)       0         \n                                                                 \n conv2d_2 (Conv2D)           (None, 39, 39, 512)       1180160   \n                                                                 \n max_pooling2d_2 (MaxPooling  (None, 13, 13, 512)      0         \n 2D)                                                             \n                                                                 \n dropout_2 (Dropout)         (None, 13, 13, 512)       0         \n                                                                 \n flatten (Flatten)           (None, 86528)             0         \n                                                                 \n dense (Dense)               (None, 128)               11075712  \n                                                                 \n dense_1 (Dense)             (None, 256)               33024     \n                                                                 \n dense_2 (Dense)             (None, 3)                 771       \n                                                                 \n=================================================================\nTotal params: 12,588,419\nTrainable params: 12,588,419\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"max_pool_model.compile(optimizer='ADAM',\n              loss = 'categorical_crossentropy',\n              metrics=['accuracy', Precision(), Recall()])","metadata":{"execution":{"iopub.status.busy":"2023-05-21T06:32:46.301162Z","iopub.execute_input":"2023-05-21T06:32:46.301537Z","iopub.status.idle":"2023-05-21T06:32:46.325787Z","shell.execute_reply.started":"2023-05-21T06:32:46.301498Z","shell.execute_reply":"2023-05-21T06:32:46.324884Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"max_pool_model_history = max_pool_model.fit(\n        class_train_data,\n        steps_per_epoch = class_train_number // BATCH_SIZE,\n        validation_data = class_valid_data,\n        validation_steps = class_valid_number // BATCH_SIZE,\n        epochs=EPOCHS,\n        batch_size=BATCH_SIZE,\n        callbacks=classification_callbacks\n    )","metadata":{"execution":{"iopub.status.busy":"2023-05-21T06:32:50.160783Z","iopub.execute_input":"2023-05-21T06:32:50.161471Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1/20\n","output_type":"stream"},{"name":"stderr","text":"2023-05-21 06:32:51.440648: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential/dropout/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":"342/342 [==============================] - 130s 363ms/step - loss: 1.4742 - accuracy: 0.4532 - precision: 0.5864 - recall: 0.1694 - val_loss: 0.8551 - val_accuracy: 0.5798 - val_precision: 0.6851 - val_recall: 0.4566\nEpoch 2/20\n342/342 [==============================] - 123s 359ms/step - loss: 0.8368 - accuracy: 0.5958 - precision: 0.6681 - recall: 0.4681 - val_loss: 0.7862 - val_accuracy: 0.6217 - val_precision: 0.6635 - val_recall: 0.5327\nEpoch 3/20\n342/342 [==============================] - 122s 356ms/step - loss: 0.7412 - accuracy: 0.6610 - precision: 0.7324 - recall: 0.5395 - val_loss: 0.7061 - val_accuracy: 0.6908 - val_precision: 0.7204 - val_recall: 0.6526\nEpoch 4/20\n153/342 [============>.................] - ETA: 54s - loss: 0.6841 - accuracy: 0.6907 - precision: 0.7473 - recall: 0.6163","output_type":"stream"}]},{"cell_type":"code","source":"plot_hist(max_pool_model_history)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Модель 2","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.applications.efficientnet import EfficientNetB4\nfrom tensorflow.keras import layers","metadata":{"execution":{"iopub.status.busy":"2023-05-21T06:25:49.832265Z","iopub.execute_input":"2023-05-21T06:25:49.832641Z","iopub.status.idle":"2023-05-21T06:25:49.841622Z","shell.execute_reply.started":"2023-05-21T06:25:49.832611Z","shell.execute_reply":"2023-05-21T06:25:49.840631Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"img_augmentation = Sequential(\n    [\n        layers.RandomRotation(factor=0.15),\n        #layers.RandomTranslation(height_factor=0.1, width_factor=0.1),\n        layers.RandomFlip('horizontal'),\n        layers.RandomContrast(factor=0.1),\n    ],\n    name=\"img_augmentation\",\n)\n\n\ndef unfreeze_model(model):\n    # We unfreeze the top 20 layers while leaving BatchNorm layers frozen\n    for layer in model.layers[-20:]:\n        if not isinstance(layer, layers.BatchNormalization):\n            layer.trainable = True\n\n    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n    model.compile(\n        optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n    )\n\n\ndef build_model(num_classes, flag=False):\n    inputs = layers.Input(shape=(IMAGE_SIZE[0], IMAGE_SIZE[0], 3))\n    x = img_augmentation(inputs)\n    model = EfficientNetB4(include_top=False, input_tensor=x, weights=\"imagenet\")\n\n    # Freeze the pretrained weights\n    model.trainable = False\n\n    # Rebuild top\n    x = layers.GlobalAveragePooling2D(name=\"avg_pool\")(model.output)\n    x = layers.BatchNormalization()(x)\n\n    top_dropout_rate = 0.2\n    x = layers.Dropout(top_dropout_rate, name=\"top_dropout\")(x)\n    outputs = layers.Dense(num_classes, activation=\"softmax\", name=\"pred\")(x)\n\n    # Compile\n    model = tf.keras.Model(inputs, outputs, name=\"EfficientNet\")\n    \n    if flag:\n        unfreeze_model(model)\n    \n    else:\n        optimizer = tf.keras.optimizers.Adam(learning_rate=1e-2)\n        model.compile(\n            optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n        )\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-05-21T06:25:52.167012Z","iopub.execute_input":"2023-05-21T06:25:52.167387Z","iopub.status.idle":"2023-05-21T06:25:52.584963Z","shell.execute_reply.started":"2023-05-21T06:25:52.167356Z","shell.execute_reply":"2023-05-21T06:25:52.583982Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"model = build_model(3, flag=True)","metadata":{"execution":{"iopub.status.busy":"2023-05-21T06:25:59.335844Z","iopub.execute_input":"2023-05-21T06:25:59.336323Z","iopub.status.idle":"2023-05-21T06:26:09.415148Z","shell.execute_reply.started":"2023-05-21T06:25:59.336282Z","shell.execute_reply":"2023-05-21T06:26:09.414214Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb4_notop.h5\n71686520/71686520 [==============================] - 4s 0us/step\n","output_type":"stream"}]},{"cell_type":"code","source":"# model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-05-21T02:46:31.400238Z","iopub.execute_input":"2023-05-21T02:46:31.400689Z","iopub.status.idle":"2023-05-21T02:46:31.407688Z","shell.execute_reply.started":"2023-05-21T02:46:31.400653Z","shell.execute_reply":"2023-05-21T02:46:31.406524Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"epochs = 40\nhist = model.fit(\n    class_train_data,\n    steps_per_epoch = class_train_number // BATCH_SIZE,\n    validation_data = class_valid_data,\n    validation_steps = class_valid_number // BATCH_SIZE,\n    epochs=EPOCHS,\n    batch_size=BATCH_SIZE,\n    callbacks=classification_callbacks\n)","metadata":{"execution":{"iopub.status.busy":"2023-05-21T06:26:14.845919Z","iopub.execute_input":"2023-05-21T06:26:14.846300Z","iopub.status.idle":"2023-05-21T06:31:07.281959Z","shell.execute_reply.started":"2023-05-21T06:26:14.846269Z","shell.execute_reply":"2023-05-21T06:31:07.280673Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"Epoch 1/20\n","output_type":"stream"},{"name":"stderr","text":"2023-05-21 06:26:29.117384: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inEfficientNet/block1b_drop/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":"342/342 [==============================] - ETA: 0s - loss: 1.1588 - accuracy: 0.3722","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[31], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m40\u001b[39m\n\u001b[0;32m----> 2\u001b[0m hist \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_train_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mclass_train_number\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mclass_valid_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mclass_valid_number\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclassification_callbacks\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n","File \u001b[0;32m/opt/conda/lib/python3.10/json/encoder.py:199\u001b[0m, in \u001b[0;36mJSONEncoder.encode\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m encode_basestring(o)\n\u001b[1;32m    196\u001b[0m \u001b[38;5;66;03m# This doesn't pass the iterator directly to ''.join() because the\u001b[39;00m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# exceptions aren't as detailed.  The list call should be roughly\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[39;00m\n\u001b[0;32m--> 199\u001b[0m chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_one_shot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(chunks, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[1;32m    201\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(chunks)\n","File \u001b[0;32m/opt/conda/lib/python3.10/json/encoder.py:257\u001b[0m, in \u001b[0;36mJSONEncoder.iterencode\u001b[0;34m(self, o, _one_shot)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    253\u001b[0m     _iterencode \u001b[38;5;241m=\u001b[39m _make_iterencode(\n\u001b[1;32m    254\u001b[0m         markers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault, _encoder, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindent, floatstr,\n\u001b[1;32m    255\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey_separator, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitem_separator, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msort_keys,\n\u001b[1;32m    256\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskipkeys, _one_shot)\n\u001b[0;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_iterencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n","\u001b[0;31mTypeError\u001b[0m: Unable to serialize [     2.0897      2.1129      2.1082] to JSON. Unrecognized type <class 'tensorflow.python.framework.ops.EagerTensor'>."],"ename":"TypeError","evalue":"Unable to serialize [     2.0897      2.1129      2.1082] to JSON. Unrecognized type <class 'tensorflow.python.framework.ops.EagerTensor'>.","output_type":"error"}]},{"cell_type":"code","source":"plot_hist(hist)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}